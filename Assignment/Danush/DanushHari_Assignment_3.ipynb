{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Import the data\n"
      ],
      "metadata": {
        "id": "4b8oKxzpM7E0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "id": "RY-Y5mOqgUum",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7f0ad9f0-a4f6-4598-fe18-4aae19cc4ca9"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator \n",
        "\n",
        "train_datagen=ImageDataGenerator(rescale=1./255,shear_range=0.2,\n",
        "                                 zoom_range=0.2,horizontal_flip=True)\n",
        "test_datagen=ImageDataGenerator(rescale=1./255)"
      ],
      "metadata": {
        "id": "MPwCYN3jgdTT"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Image Augmentation"
      ],
      "metadata": {
        "id": "gHTw875hOX24"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = train_datagen.flow_from_directory('/content/gdrive/MyDrive/flowers',\n",
        "                                       target_size=(64,64),\n",
        "                                       class_mode='categorical',\n",
        "                                       batch_size=100)"
      ],
      "metadata": {
        "id": "mMDHihaDg17x",
        "outputId": "3a562ebf-7939-4e47-a9c7-7197d766bbd5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 4317 images belonging to 5 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_test=test_datagen.flow_from_directory(\"/content/gdrive/MyDrive/flowers\",target_size=(64,64),class_mode='categorical',batch_size=24)"
      ],
      "metadata": {
        "id": "TzqCE1GahAku",
        "outputId": "7c346339-d7da-4dc9-f1d7-32131647eb64",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 4317 images belonging to 5 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train.class_indices"
      ],
      "metadata": {
        "id": "Tspy-ZanhBAN",
        "outputId": "43723c38-3966-4297-9c84-43bb2cfa85ea",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'daisy': 0, 'dandelion': 1, 'rose': 2, 'sunflower': 3, 'tulip': 4}"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Convolution2D, MaxPooling2D, Dense, Flatten\n",
        "from keras.callbacks import EarlyStopping, ReduceLROnPlateau"
      ],
      "metadata": {
        "id": "1Tbo4AgJhPSq"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **INITIALISING AND CREATING MODEL**"
      ],
      "metadata": {
        "id": "WJ7VUv9BhSi0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Convolution2D(32,(3,3),activation='relu',input_shape=(64,64,3)))\n",
        "model.add(MaxPooling2D((2,2)))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(300,activation='relu'))\n",
        "model.add(Dense(150,activation='relu'))\n",
        "model.add(Dense(5,activation='softmax'))\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "lXhW_LbphRai",
        "outputId": "98d061bf-222e-4a96-d53f-3ea126a92046",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 62, 62, 32)        896       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 31, 31, 32)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 30752)             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 300)               9225900   \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 150)               45150     \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 5)                 755       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 9,272,701\n",
            "Trainable params: 9,272,701\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "mpmxayj1hXwl"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit_generator(x_train,steps_per_epoch=len(x_train), validation_data=x_test, validation_steps=len(x_test), epochs= 30)"
      ],
      "metadata": {
        "id": "PFsr4_sThbBw",
        "outputId": "29191fd2-6a2e-42b1-d78f-181c84827296",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "44/44 [==============================] - 1198s 27s/step - loss: 1.7670 - accuracy: 0.3574 - val_loss: 1.1815 - val_accuracy: 0.5008\n",
            "Epoch 2/30\n",
            "44/44 [==============================] - 54s 1s/step - loss: 1.1316 - accuracy: 0.5363 - val_loss: 1.1560 - val_accuracy: 0.5210\n",
            "Epoch 3/30\n",
            "44/44 [==============================] - 54s 1s/step - loss: 1.0400 - accuracy: 0.5847 - val_loss: 0.9855 - val_accuracy: 0.6166\n",
            "Epoch 4/30\n",
            "44/44 [==============================] - 54s 1s/step - loss: 0.9853 - accuracy: 0.6145 - val_loss: 0.9951 - val_accuracy: 0.6238\n",
            "Epoch 5/30\n",
            "44/44 [==============================] - 54s 1s/step - loss: 0.9483 - accuracy: 0.6368 - val_loss: 0.9216 - val_accuracy: 0.6620\n",
            "Epoch 6/30\n",
            "44/44 [==============================] - 54s 1s/step - loss: 0.9200 - accuracy: 0.6384 - val_loss: 0.8748 - val_accuracy: 0.6644\n",
            "Epoch 7/30\n",
            "44/44 [==============================] - 53s 1s/step - loss: 0.8649 - accuracy: 0.6699 - val_loss: 0.7901 - val_accuracy: 0.7098\n",
            "Epoch 8/30\n",
            "44/44 [==============================] - 54s 1s/step - loss: 0.8380 - accuracy: 0.6762 - val_loss: 0.8823 - val_accuracy: 0.6583\n",
            "Epoch 9/30\n",
            "44/44 [==============================] - 54s 1s/step - loss: 0.7936 - accuracy: 0.6977 - val_loss: 0.8195 - val_accuracy: 0.6931\n",
            "Epoch 10/30\n",
            "44/44 [==============================] - 54s 1s/step - loss: 0.7702 - accuracy: 0.7088 - val_loss: 0.7886 - val_accuracy: 0.7060\n",
            "Epoch 11/30\n",
            "44/44 [==============================] - 54s 1s/step - loss: 0.7270 - accuracy: 0.7250 - val_loss: 0.7067 - val_accuracy: 0.7378\n",
            "Epoch 12/30\n",
            "44/44 [==============================] - 54s 1s/step - loss: 0.7062 - accuracy: 0.7299 - val_loss: 0.7277 - val_accuracy: 0.7338\n",
            "Epoch 13/30\n",
            "44/44 [==============================] - 54s 1s/step - loss: 0.7207 - accuracy: 0.7199 - val_loss: 0.6623 - val_accuracy: 0.7464\n",
            "Epoch 14/30\n",
            "44/44 [==============================] - 54s 1s/step - loss: 0.6783 - accuracy: 0.7452 - val_loss: 0.6552 - val_accuracy: 0.7584\n",
            "Epoch 15/30\n",
            "44/44 [==============================] - 54s 1s/step - loss: 0.6291 - accuracy: 0.7649 - val_loss: 0.5923 - val_accuracy: 0.7820\n",
            "Epoch 16/30\n",
            "44/44 [==============================] - 54s 1s/step - loss: 0.6075 - accuracy: 0.7751 - val_loss: 0.6215 - val_accuracy: 0.7670\n",
            "Epoch 17/30\n",
            "44/44 [==============================] - 55s 1s/step - loss: 0.6105 - accuracy: 0.7700 - val_loss: 0.5874 - val_accuracy: 0.7806\n",
            "Epoch 18/30\n",
            "44/44 [==============================] - 55s 1s/step - loss: 0.6032 - accuracy: 0.7748 - val_loss: 0.5833 - val_accuracy: 0.7769\n",
            "Epoch 19/30\n",
            "44/44 [==============================] - 54s 1s/step - loss: 0.5641 - accuracy: 0.7918 - val_loss: 0.6373 - val_accuracy: 0.7697\n",
            "Epoch 20/30\n",
            "44/44 [==============================] - 54s 1s/step - loss: 0.5191 - accuracy: 0.8040 - val_loss: 0.4446 - val_accuracy: 0.8376\n",
            "Epoch 21/30\n",
            "44/44 [==============================] - 54s 1s/step - loss: 0.5148 - accuracy: 0.8038 - val_loss: 0.4783 - val_accuracy: 0.8216\n",
            "Epoch 22/30\n",
            "44/44 [==============================] - 54s 1s/step - loss: 0.5171 - accuracy: 0.8073 - val_loss: 0.3808 - val_accuracy: 0.8659\n",
            "Epoch 23/30\n",
            "44/44 [==============================] - 55s 1s/step - loss: 0.4879 - accuracy: 0.8221 - val_loss: 0.3838 - val_accuracy: 0.8582\n",
            "Epoch 24/30\n",
            "44/44 [==============================] - 54s 1s/step - loss: 0.4354 - accuracy: 0.8351 - val_loss: 0.3471 - val_accuracy: 0.8768\n",
            "Epoch 25/30\n",
            "44/44 [==============================] - 54s 1s/step - loss: 0.4475 - accuracy: 0.8372 - val_loss: 0.3437 - val_accuracy: 0.8691\n",
            "Epoch 26/30\n",
            "44/44 [==============================] - 54s 1s/step - loss: 0.4662 - accuracy: 0.8307 - val_loss: 0.4308 - val_accuracy: 0.8362\n",
            "Epoch 27/30\n",
            "44/44 [==============================] - 54s 1s/step - loss: 0.4386 - accuracy: 0.8429 - val_loss: 0.4306 - val_accuracy: 0.8457\n",
            "Epoch 28/30\n",
            "44/44 [==============================] - 55s 1s/step - loss: 0.4133 - accuracy: 0.8483 - val_loss: 0.4244 - val_accuracy: 0.8443\n",
            "Epoch 29/30\n",
            "44/44 [==============================] - 55s 1s/step - loss: 0.3958 - accuracy: 0.8566 - val_loss: 0.3552 - val_accuracy: 0.8675\n",
            "Epoch 30/30\n",
            "44/44 [==============================] - 54s 1s/step - loss: 0.3872 - accuracy: 0.8559 - val_loss: 0.2364 - val_accuracy: 0.9166\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f36a5767810>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **SAVE THE MODEL**"
      ],
      "metadata": {
        "id": "qj90rcUThiwa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# save model\n",
        "model.save('flowers.h5')"
      ],
      "metadata": {
        "id": "ZzJ-z-OKhdL6"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test the model"
      ],
      "metadata": {
        "id": "HLKVwf_gtp4m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.preprocessing import image"
      ],
      "metadata": {
        "id": "40iUSUvotuAl"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model=load_model('flowers.h5')"
      ],
      "metadata": {
        "id": "5H4otwOqtuwu"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val = list(x_train.class_indices.keys())\n",
        "val"
      ],
      "metadata": {
        "id": "tN2ZZtlEt2hz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2685acee-5ece-442a-fd4b-84c3e48a0a33"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['daisy', 'dandelion', 'rose', 'sunflower', 'tulip']"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "img=image.load_img(\"/content/gdrive/MyDrive/flowers/daisy/2535769822_513be6bbe9.jpg\",target_size=(64,64))\n",
        "x=image.img_to_array(img)\n",
        "x=np.expand_dims(x,axis=0)\n",
        "y=np.argmax(model.predict(x),axis=1)\n",
        "\n",
        "index=['daisy','dandelion','rose','sunflower','tulip']\n",
        "index[y[0]]"
      ],
      "metadata": {
        "id": "Fa4rxzQqt4pu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "df318e7b-0bf4-47e9-b3ab-703a80b7b0e3"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'daisy'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}